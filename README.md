# adu

<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->

This file will become your README and also the index of your
documentation.

## Install

``` sh
pip install adu4
```

## How to use

First collect html pages, than run bs4 to process data

``` python
# Create a Selenium web driver instance (e.g., using Chrome)
from selenium import webdriver
import time
from selenium import webdriver
driver = webdriver.Chrome()

# Set the desired Twitter page URL
twitter_url = "https://twitter.com/LulaOficial"  # Replace with the actual URL of the Twitter page

# Scrape the Twitter page
scrape_twitter_page(driver, twitter_url, scroll_limit=3, sleep_time=15) #sleep time is important to give time to each log in per driver session

# Close the web driver
#driver.quit()
```

``` python
import glob
from bs4 import BeautifulSoup

file_paths = glob.glob('*.html')

for file_path in file_paths:
    print(file_path)
    tweets = extract_tweets_from_file(file_path)    
    for tweet in tweets:
            print(file_path, tweet)
```
